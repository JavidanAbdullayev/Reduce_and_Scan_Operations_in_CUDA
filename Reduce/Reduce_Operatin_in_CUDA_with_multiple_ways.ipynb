{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reduce_Operatin_in_CUDA_with_multiple_ways.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Im4KlaVX2T",
        "outputId": "99f33466-9c5a-4fcb-9f9d-12b398118a8a"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-joj1pcxy\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-joj1pcxy\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=213d290f802b04ffab32d6894e75694bfdf512e825139868f298c0b342cf3760\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4t6nnhc3/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1YkHZjbVeWg",
        "outputId": "991625df-33f7-4d84-883d-6a21c9e920ec"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2W-NbJtcT99",
        "outputId": "e325fe5d-9c4c-4597-d909-00017c747a47"
      },
      "source": [
        "%%cu\n",
        "#include <cuda.h>\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "#define N 10\n",
        "\n",
        "// #Interleaved (divergence)\n",
        "__global__ void reduce_1(int* g_idata, int* g_odata){\n",
        "  \n",
        "  extern __shared__ int sdata[];\n",
        "  // #Each thread loads one element from global to shared memory\n",
        "  int tid = threadIdx.x;\n",
        "  int i = blockIdx.x*blockDim.x  + threadIdx.x;\n",
        "  sdata[tid] = g_idata[i];\n",
        "\n",
        "  __syncthreads();  \n",
        "  \n",
        "  // #Do reduction in shared memory\n",
        "  int dim = blockDim.x;\n",
        "  for (int s=2; s<=dim; s=s*2){\n",
        "      if (tid%s == 0)\n",
        "          sdata[tid] += sdata[tid+(s/2)];\n",
        "          \n",
        "      __syncthreads();\n",
        "  }\n",
        "\n",
        "  // #Write result for this block to global memory\n",
        "  if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "// # bank conflicts\n",
        "__global__ void reduce_2(int* g_idata, int* g_odata){\n",
        "  \n",
        "  extern __shared__ int sdata[];\n",
        "  // #Each thread loads one element from global to shared memory\n",
        "  int tid = threadIdx.x;\n",
        "  int i = blockIdx.x*blockDim.x  + threadIdx.x;\n",
        "  sdata[tid] = g_idata[i];\n",
        "\n",
        "  __syncthreads();  \n",
        "  \n",
        "  // #Do reduction in shared memory\n",
        "  int index ;\n",
        "  for (unsigned int s=1; s<blockDim.x; s*=2){\n",
        "       index = 2 * s * tid;\n",
        "      \n",
        "      if (index < blockDim.x)  sdata[index] += sdata[index+s];\n",
        "     \n",
        "      __syncthreads();\n",
        "  }\n",
        "\n",
        "  // #Write result for this block to global memory\n",
        "  if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n",
        "\n",
        "}\n",
        "\n",
        "# // suquential reduce\n",
        "__global__ void reduce_3(int* g_idata, int* g_odata){\n",
        "  \n",
        "  extern __shared__ int sdata[];\n",
        "  // #Each thread loads one element from global to shared memory\n",
        "  int tid = threadIdx.x;\n",
        "  int i = blockIdx.x*blockDim.x  + threadIdx.x;\n",
        "  sdata[tid] = g_idata[i];\n",
        "\n",
        "  __syncthreads();  \n",
        "  // #Do reduction in shared memory\n",
        "  for (int s=blockDim.x/2; s>0; s=s/2){\n",
        "      if (tid < s){\n",
        "          sdata[tid] += sdata[tid+s];\n",
        "      }\n",
        "            \n",
        "      __syncthreads();\n",
        "  }\n",
        "  // #Write result for this block to global memory\n",
        "  if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "# // Using shared memeory\n",
        "__global__ void reduce_4(int* g_idata, int* g_odata){\n",
        "  \n",
        "  extern __shared__ int sdata[];\n",
        "  // #Each thread loads one element from global to shared memory\n",
        "  int tid = threadIdx.x;\n",
        "  int i = blockIdx.x*blockDim.x  + threadIdx.x;\n",
        "  sdata[tid] = g_idata[i] + g_idata[1023-i];\n",
        "\n",
        "  __syncthreads();  \n",
        "  \n",
        " // #Do reduction in shared memory\n",
        "  for (int s=blockDim.x/2; s>0; s=s/2){\n",
        "      if (tid < s){\n",
        "          sdata[tid] += sdata[tid+s];\n",
        "      }\n",
        "            \n",
        "      __syncthreads();\n",
        "  }\n",
        "  // #Write result for this block to global memory\n",
        "  if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  \n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "  const int count = 1024;\n",
        "  const int size = count * sizeof(int);\n",
        "  int h[1024];\n",
        "  for (int i = 0; i < 1024; i++) {\n",
        "        h[i] = 1;\n",
        "    }\n",
        "\n",
        "  int* d, * g, result;\n",
        "  \n",
        "  cudaMalloc(&d, size);\n",
        "  cudaMalloc(&g, sizeof(int));\n",
        "  cudaMemcpy(d, h, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  cudaEventRecord(start,0);\n",
        "\n",
        "  reduce_4<<<1, count/2, count*sizeof(int)>>>(d, g);\n",
        "\n",
        "  cudaEventRecord(stop,0);\n",
        "  \n",
        "  cudaMemcpy(&result, g, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  float diff;\n",
        "  cudaEventElapsedTime(&diff, start, stop);\n",
        "  cout<<endl<<\"\\nTime: \"<< diff;\n",
        "\n",
        "  \n",
        "  cout << \"\\nSum is \" << result << endl;\n",
        "  \n",
        "  cudaFree(d);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Time: 0.020448\n",
            "Sum is 1024\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT2gh2Lgd3Qz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}